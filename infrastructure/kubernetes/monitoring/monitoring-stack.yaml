# Monitoring Stack for HarmonyFlow
# Components: Prometheus, Grafana, Loki, AlertManager

---
# Namespace for Monitoring
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: observability

---
# Prometheus Operator HelmRelease
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: prometheus
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "52.0.0"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  values:
    prometheus:
      prometheusSpec:
        replicas: 2
        retention: 30d
        retentionSize: "50GB"
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: gp3
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 100Gi
        serviceMonitorSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        ruleSelectorNilUsesHelmValues: false
        ruleSelector: {}
        enableAdminAPI: false
        walCompression: true
        
    alertmanager:
      enabled: true
      config:
        global:
          smtp_smarthost: 'smtp.gmail.com:587'
          smtp_from: 'alerts@harmonyflow.io'
          smtp_auth_username: 'alerts@harmonyflow.io'
          smtp_auth_password: 'CHANGE_ME'
          
        route:
          group_by: ['alertname', 'severity']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 4h
          receiver: 'slack'
          routes:
            - match:
                severity: critical
              receiver: 'pagerduty'
            - match:
                severity: warning
              receiver: 'slack'
              
        receivers:
          - name: 'slack'
            slack_configs:
              - api_url: 'https://hooks.slack.com/services/CHANGE/ME/PLEASE'
                channel: '#alerts'
                title: 'HarmonyFlow Alert'
                text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
                
          - name: 'pagerduty'
            pagerduty_configs:
              - service_key: 'CHANGE_ME'
                severity: critical
                
      alertmanagerSpec:
        replicas: 2
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
            
    grafana:
      enabled: true
      admin:
        existingSecret: grafana-admin-credentials
      resources:
        requests:
          cpu: 200m
          memory: 256Mi
        limits:
          cpu: 500m
          memory: 512Mi
      persistence:
        enabled: true
        storageClassName: gp3
        size: 10Gi
      dashboards:
        default:
          harmonyflow-overview:
            url: https://raw.githubusercontent.com/harmonyflow/dashboards/main/overview.json
            token: ''
          harmonyflow-sessions:
            url: https://raw.githubusercontent.com/harmonyflow/dashboards/main/sessions.json
            token: ''
          harmonyflow-infrastructure:
            url: https://raw.githubusercontent.com/harmonyflow/dashboards/main/infrastructure.json
            token: ''
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: 'default'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/default
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              url: http://prometheus-kube-prometheus-prometheus:9090
              access: proxy
              isDefault: true
            - name: Loki
              type: loki
              url: http://loki:3100
              access: proxy
            - name: Tempo
              type: tempo
              url: http://tempo:3100
              access: proxy
              
    kubeStateMetrics:
      enabled: true
      resources:
        requests:
          cpu: 50m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi
          
    nodeExporter:
      enabled: true
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 100m
          memory: 128Mi

---
# Loki HelmRelease
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      chart: loki
      version: "5.35.0"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  values:
    deploymentMode: SimpleScalable
    
    loki:
      auth_enabled: false
      commonConfig:
        replication_factor: 2
      storage:
        type: s3
        bucketNames:
          chunks: harmonyflow-loki-chunks
          ruler: harmonyflow-loki-ruler
          admin: harmonyflow-loki-admin
        s3:
          endpoint: s3.us-west-2.amazonaws.com
          region: us-west-2
          insecure: false
      schemaConfig:
        configs:
          - from: "2023-01-01"
            store: boltdb-shipper
            object_store: s3
            schema: v11
            index:
              prefix: loki_index_
              period: 24h
      limits_config:
        retention_period: 168h  # 7 days
        ingestion_rate_mb: 10
        ingestion_burst_size_mb: 20
        per_stream_rate_limit: 5MB
        per_stream_rate_limit_burst: 20MB
        max_global_streams_per_user: 10000
        
    gateway:
      enabled: true
      replicas: 2
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi
          
    read:
      replicas: 2
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 500m
          memory: 1Gi
          
    write:
      replicas: 2
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 500m
          memory: 1Gi

---
# Promtail HelmRelease (Log Collector)
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: promtail
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      chart: promtail
      version: "6.15.0"
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  values:
    config:
      serverPort: 3101
      clients:
        - url: http://loki-gateway.monitoring.svc.cluster.local/loki/api/v1/push
      snippets:
        pipelineStages:
          - docker: {}
          - cri: {}
          - match:
              selector: '{app="session-state-service"}'
              stages:
                - json:
                    expressions:
                      level: level
                      message: message
                      session_id: session_id
          - match:
              selector: '{app="content-delivery-service"}'
              stages:
                - json:
                    expressions:
                      level: level
                      message: message
                      user_id: user_id
          - timestamp:
              source: time
              format: RFC3339
          - labels:
              level:
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

---
# Secret for Grafana Admin Credentials
apiVersion: v1
kind: Secret
metadata:
  name: grafana-admin-credentials
  namespace: monitoring
type: Opaque
stringData:
  admin-user: admin
  admin-password: "CHANGE_ME_IN_PRODUCTION"

---
# Prometheus Rules for HarmonyFlow
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: harmonyflow-alerts
  namespace: monitoring
  labels:
    release: prometheus
spec:
  groups:
    - name: harmonyflow
      rules:
        # Session State Service Alerts
        - alert: SessionStateServiceHighErrorRate
          expr: |
            (
              sum(rate(http_requests_total{job="session-state-service",status=~"5.."}[5m]))
              /
              sum(rate(http_requests_total{job="session-state-service"}[5m]))
            ) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Session State Service has high error rate"
            description: "Error rate is above 5% for more than 5 minutes"
            
        - alert: SessionStateServiceHighLatency
          expr: |
            histogram_quantile(0.99, 
              sum(rate(http_request_duration_seconds_bucket{job="session-state-service"}[5m])) by (le)
            ) > 0.1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Session State Service has high latency"
            description: "P99 latency is above 100ms"
            
        # Redis Cluster Alerts
        - alert: RedisDown
          expr: up{job="redis-metrics"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Redis node is down"
            description: "Redis node {{ $labels.instance }} has been down for more than 1 minute"
            
        - alert: RedisMemoryHigh
          expr: |
            redis_memory_used_bytes / redis_memory_max_bytes > 0.8
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Redis memory usage is high"
            description: "Redis memory usage is above 80%"
            
        # PostgreSQL Alerts
        - alert: PostgreSQLDown
          expr: up{job="postgresql-metrics"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "PostgreSQL is down"
            description: "PostgreSQL instance {{ $labels.instance }} has been down for more than 1 minute"
            
        - alert: PostgreSQLReplicationLag
          expr: |
            pg_replication_lag > 300
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "PostgreSQL replication lag is high"
            description: "Replication lag is above 5 minutes"
            
        # RabbitMQ Alerts
        - alert: RabbitMQNodeDown
          expr: rabbitmq_up == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "RabbitMQ node is down"
            description: "RabbitMQ node {{ $labels.instance }} has been down for more than 1 minute"
            
        - alert: RabbitMQQueueBuildup
          expr: |
            rabbitmq_queue_messages_ready > 10000
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "RabbitMQ queue has message buildup"
            description: "Queue {{ $labels.queue }} has more than 10,000 messages ready"
            
        # Infrastructure Alerts
        - alert: HighCPUUsage
          expr: |
            100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100) > 80
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage detected"
            description: "CPU usage is above 80% for more than 10 minutes"
            
        - alert: HighMemoryUsage
          expr: |
            (
              1 - (
                node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes
              )
            ) * 100 > 85
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage detected"
            description: "Memory usage is above 85% for more than 10 minutes"
            
        - alert: DiskSpaceLow
          expr: |
            (
              node_filesystem_avail_bytes{mountpoint="/"} /
              node_filesystem_size_bytes{mountpoint="/"}
            ) * 100 < 10
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Disk space is running low"
            description: "Disk usage is above 90%"

---
# Network Policy for Monitoring
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-network-policy
  namespace: monitoring
spec:
  podSelector: {}
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: harmonyflow
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 9090
        - protocol: TCP
          port: 3000
        - protocol: TCP
          port: 9093
  egress:
    - to: []
      ports:
        - protocol: TCP
          port: 443
        - protocol: TCP
          port: 587
